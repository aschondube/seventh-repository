{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 7.1 - Scraping\n",
    "\n",
    "The aim of this task is to obtain news headers from the financial times about BTC, so that they can be connected to the BTC price data obtained via AlphaVantage's API to derive insights into what may have influenced price fluctuations.\n",
    "\n",
    "This notebook will only be used to retrieve the data from the FT via scrapping as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import *\n",
    "import os\n",
    "import lxml\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date                                              Title\n",
      "0   2024-05-30     European bitcoin ETPs suffer mounting outflows\n",
      "1   2024-05-24  British-Chinese bitcoin money launderer jailed...\n",
      "2   2024-05-24                      Cryptofinance: into the ether\n",
      "3   2024-05-23  SEC paves way for ethereum ETFs in boost for c...\n",
      "4   2024-05-22           First UK crypto ETPs to launch on May 28\n",
      "..         ...                                                ...\n",
      "100 2023-12-07                               The return of crypto\n",
      "101 2023-12-05                       Bitcoin’s bounceback déjà vu\n",
      "102 2023-12-05                     The jobs market is still tight\n",
      "103 2023-12-05  Buying frenzy puts some Grayscale crypto funds...\n",
      "104 2023-12-04  Bitcoin price surges above $42,000 as rate cut...\n",
      "\n",
      "[105 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def scrape_ft_bitcoin_articles():\n",
    "    # Base URL of the Financial Times Bitcoin page\n",
    "    base_url = 'https://www.ft.com/bitcoin'\n",
    "    \n",
    "    # Initialize the page counter\n",
    "    page_number = 1\n",
    "    \n",
    "    # Prepare lists to store the extracted data\n",
    "    article_dates = []\n",
    "    article_titles = []\n",
    "    \n",
    "    # Define the cutoff date (exactly 6 months ago from today)\n",
    "    cutoff_date = datetime.now().date() - relativedelta(months=6)\n",
    "\n",
    "    while True:\n",
    "        # Construct the URL for the current page\n",
    "        url = f'{base_url}?page={page_number}'\n",
    "        \n",
    "        # Make the HTTP request\n",
    "        result = requests.get(url)\n",
    "        \n",
    "        # Parse the HTML using BeautifulSoup\n",
    "        soup = bs4.BeautifulSoup(result.text, 'html.parser')\n",
    "        \n",
    "        # Extract dates and titles\n",
    "        dates = soup.select('time.o-date')\n",
    "        titles = soup.select('a.js-teaser-heading-link')\n",
    "        \n",
    "        # Extract date and title text\n",
    "        for date, title in zip(dates, titles):\n",
    "            # Parse the date to keep only the date component\n",
    "            parsed_date = datetime.fromisoformat(date.get('datetime')).date()\n",
    "            \n",
    "            # Check if the article date is within the last 6 months\n",
    "            if parsed_date < cutoff_date:\n",
    "                df = pd.DataFrame({\n",
    "                    'Date': article_dates,\n",
    "                    'Title': article_titles\n",
    "                })\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                return df\n",
    "            \n",
    "            article_dates.append(parsed_date)\n",
    "            article_titles.append(title.get_text(strip=True))\n",
    "        \n",
    "        # Check for the presence of the \"next page\" link\n",
    "        next_page_link = soup.find('a', class_='o-buttons-icon--arrow-right')\n",
    "        \n",
    "        # If there is no link to the next page, break out of the loop\n",
    "        if not next_page_link:\n",
    "            break\n",
    "        \n",
    "        # Increment the page number for the next iteration\n",
    "        page_number += 1\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Date': article_dates,\n",
    "        'Title': article_titles\n",
    "    })\n",
    "    \n",
    "    # Ensure the Date column is in datetime dtype\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Call the function and print the DataFrame\n",
    "bitcoin_articles_df = scrape_ft_bitcoin_articles()\n",
    "print(bitcoin_articles_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    105 non-null    datetime64[ns]\n",
      " 1   Title   105 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 1.8+ KB\n"
     ]
    }
   ],
   "source": [
    "bitcoin_articles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>European bitcoin ETPs suffer mounting outflows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>British-Chinese bitcoin money launderer jailed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>Cryptofinance: into the ether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>SEC paves way for ethereum ETFs in boost for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>First UK crypto ETPs to launch on May 28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Title\n",
       "0  2024-05-30     European bitcoin ETPs suffer mounting outflows\n",
       "1  2024-05-24  British-Chinese bitcoin money launderer jailed...\n",
       "2  2024-05-24                      Cryptofinance: into the ether\n",
       "3  2024-05-23  SEC paves way for ethereum ETFs in boost for c...\n",
       "4  2024-05-22           First UK crypto ETPs to launch on May 28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date                                              Title\n",
      "0    2024-05-30     European bitcoin ETPs suffer mounting outflows\n",
      "1    2024-05-24  British-Chinese bitcoin money launderer jailed...\n",
      "2    2024-05-24                      Cryptofinance: into the ether\n",
      "3    2024-05-23  SEC paves way for ethereum ETFs in boost for c...\n",
      "4    2024-05-22           First UK crypto ETPs to launch on May 28\n",
      "..          ...                                                ...\n",
      "100  2023-12-07                               The return of crypto\n",
      "101  2023-12-05                       Bitcoin’s bounceback déjà vu\n",
      "102  2023-12-05                     The jobs market is still tight\n",
      "103  2023-12-05  Buying frenzy puts some Grayscale crypto funds...\n",
      "104  2023-12-04  Bitcoin price surges above $42,000 as rate cut...\n",
      "\n",
      "[105 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def scrape_ft_bitcoin_articles():\n",
    "    # Base URL of the Financial Times Bitcoin page\n",
    "    base_url = 'https://www.ft.com/bitcoin'\n",
    "    \n",
    "    # Initialize the page counter\n",
    "    page_number = 1\n",
    "    \n",
    "    # Prepare lists to store the extracted data\n",
    "    article_dates = []\n",
    "    article_titles = []\n",
    "    \n",
    "    # Define the cutoff date (6 months ago from today)\n",
    "    cutoff_date = datetime.now().date() - timedelta(days=6*30)  # Approximation of 6 months\n",
    "\n",
    "    while True:\n",
    "        # Construct the URL for the current page\n",
    "        url = f'{base_url}?page={page_number}'\n",
    "        \n",
    "        # Make the HTTP request\n",
    "        result = requests.get(url)\n",
    "        \n",
    "        # Parse the HTML using BeautifulSoup\n",
    "        soup = bs4.BeautifulSoup(result.text, 'html.parser')\n",
    "        \n",
    "        # Extract dates and titles\n",
    "        dates = soup.select('time.o-date')\n",
    "        titles = soup.select('a.js-teaser-heading-link')\n",
    "        \n",
    "        # Extract date and title text\n",
    "        for date, title in zip(dates, titles):\n",
    "            # Parse the date to keep only the date component\n",
    "            parsed_date = datetime.fromisoformat(date.get('datetime')).date()\n",
    "            \n",
    "            # Check if the article date is within the last 6 months\n",
    "            if parsed_date < cutoff_date:\n",
    "                return pd.DataFrame({\n",
    "                    'Date': article_dates,\n",
    "                    'Title': article_titles\n",
    "                })\n",
    "            \n",
    "            article_dates.append(parsed_date)\n",
    "            article_titles.append(title.get_text(strip=True))\n",
    "        \n",
    "        # Check for the presence of the \"next page\" link\n",
    "        next_page_link = soup.find('a', class_='o-buttons-icon--arrow-right')\n",
    "        \n",
    "        # If there is no link to the next page, break out of the loop\n",
    "        if not next_page_link:\n",
    "            break\n",
    "        \n",
    "        # Increment the page number for the next iteration\n",
    "        page_number += 1\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Date': article_dates,\n",
    "        'Title': article_titles\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Call the function and print the DataFrame\n",
    "bitcoin_articles_df = scrape_ft_bitcoin_articles()\n",
    "print(bitcoin_articles_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date                                              Title\n",
      "0    2024-05-30     European bitcoin ETPs suffer mounting outflows\n",
      "1    2024-05-24  British-Chinese bitcoin money launderer jailed...\n",
      "2    2024-05-24                      Cryptofinance: into the ether\n",
      "3    2024-05-23  SEC paves way for ethereum ETFs in boost for c...\n",
      "4    2024-05-22           First UK crypto ETPs to launch on May 28\n",
      "..          ...                                                ...\n",
      "100  2023-12-07                               The return of crypto\n",
      "101  2023-12-05                       Bitcoin’s bounceback déjà vu\n",
      "102  2023-12-05                     The jobs market is still tight\n",
      "103  2023-12-05  Buying frenzy puts some Grayscale crypto funds...\n",
      "104  2023-12-04  Bitcoin price surges above $42,000 as rate cut...\n",
      "\n",
      "[105 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def scrape_ft_bitcoin_articles():\n",
    "    # Base URL of the Financial Times Bitcoin page\n",
    "    base_url = 'https://www.ft.com/bitcoin'\n",
    "    \n",
    "    # Initialize the page counter\n",
    "    page_number = 1\n",
    "    \n",
    "    # Prepare lists to store the extracted data\n",
    "    article_dates = []\n",
    "    article_titles = []\n",
    "    \n",
    "    # Define the cutoff date (exactly 6 months ago from today)\n",
    "    cutoff_date = datetime.now().date() - relativedelta(months=6)\n",
    "\n",
    "    while True:\n",
    "        # Construct the URL for the current page\n",
    "        url = f'{base_url}?page={page_number}'\n",
    "        \n",
    "        # Make the HTTP request\n",
    "        result = requests.get(url)\n",
    "        \n",
    "        # Parse the HTML using BeautifulSoup\n",
    "        soup = bs4.BeautifulSoup(result.text, 'html.parser')\n",
    "        \n",
    "        # Extract dates and titles\n",
    "        dates = soup.select('time.o-date')\n",
    "        titles = soup.select('a.js-teaser-heading-link')\n",
    "        \n",
    "        # Extract date and title text\n",
    "        for date, title in zip(dates, titles):\n",
    "            # Parse the date to keep only the date component\n",
    "            parsed_date = datetime.fromisoformat(date.get('datetime')).date()\n",
    "            \n",
    "            # Check if the article date is within the last 6 months\n",
    "            if parsed_date < cutoff_date:\n",
    "                return pd.DataFrame({\n",
    "                    'Date': article_dates,\n",
    "                    'Title': article_titles\n",
    "                })\n",
    "            \n",
    "            article_dates.append(parsed_date)\n",
    "            article_titles.append(title.get_text(strip=True))\n",
    "        \n",
    "        # Check for the presence of the \"next page\" link\n",
    "        next_page_link = soup.find('a', class_='o-buttons-icon--arrow-right')\n",
    "        \n",
    "        # If there is no link to the next page, break out of the loop\n",
    "        if not next_page_link:\n",
    "            break\n",
    "        \n",
    "        # Increment the page number for the next iteration\n",
    "        page_number += 1\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Date': article_dates,\n",
    "        'Title': article_titles\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Call the function and print the DataFrame\n",
    "bitcoin_articles_df = scrape_ft_bitcoin_articles()\n",
    "print(bitcoin_articles_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    105 non-null    object\n",
      " 1   Title   105 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.8+ KB\n"
     ]
    }
   ],
   "source": [
    "bitcoin_articles_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
